{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28d3bc16-fdb3-462d-ad23-58201a69c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ccf8d-a9d1-4aec-ac29-ddda16c98563",
   "metadata": {},
   "source": [
    "Prepare training data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22128f42-60b5-460e-8402-3ae3779b034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 223074 files [03:09, 1175.60 files/s]\n"
     ]
    }
   ],
   "source": [
    "train_src = \"asl_alphabet_train\"\n",
    "train_dir = 'datasets/train'\n",
    "val_dir = 'datasets/val'\n",
    "test_dir  = 'datasets/test'\n",
    "splitfolders.ratio(train_src, output=\"datasets\",\n",
    "    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False) # 產生trian(訓練集)、val(驗證集)、test(測試集)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2cc7e-34ca-4582-a29b-0f1c2480ce9d",
   "metadata": {},
   "source": [
    "Preprocessing and Get labels\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "596d4336-904f-47a3-b371-8b82ddb9d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class dataconfig:\n",
    "    batch_size: int = 16\n",
    "    target_size: Tuple[int, int] = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c3e9b53-c4ab-4fcc-a865-a5e1f2a28b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 178447 images belonging to 29 classes.\n",
      "Found 22296 images belonging to 29 classes.\n",
      "Found 22332 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "val_datagen   = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory( # 多目錄時，目錄名為標籤\n",
    "        train_dir,\n",
    "        target_size=dataconfig.target_size,\n",
    "        batch_size=dataconfig.batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=dataconfig.target_size,\n",
    "        batch_size=dataconfig.batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=dataconfig.target_size,\n",
    "        batch_size=dataconfig.batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c3c1a83-d7ad-4925-ac8e-b0aaad8e377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "labels = list(train_generator.class_indices.keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8b34c-5b13-436f-8065-fcdebe80024c",
   "metadata": {},
   "source": [
    "Model\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76587e37-2803-425f-9eed-714cf6f31b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class modelconfig:\n",
    "    num_classes: int = len(labels)\n",
    "    input_shape: Tuple[int,int,int] = (224,224,1)\n",
    "    dropout: float = 0.1\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class traingingconfig:\n",
    "    checkpoint_path: str = \"model/B_best_mode1.keras\"\n",
    "    epochs: int = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2fbb545-abd9-481a-932f-bd3d14f14db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0379 - loss: 3.4853\n",
      "Epoch 1: val_accuracy improved from -inf to 0.03723, saving model to model/B_best_model_V1_3.keras\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 34ms/step - accuracy: 0.0379 - loss: 3.4853 - val_accuracy: 0.0372 - val_loss: 3.3582\n",
      "Epoch 2/15\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0378 - loss: 3.3585\n",
      "Epoch 2: val_accuracy did not improve from 0.03723\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 33ms/step - accuracy: 0.0378 - loss: 3.3585 - val_accuracy: 0.0365 - val_loss: 3.3582\n",
      "Epoch 3/15\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0374 - loss: 3.3590\n",
      "Epoch 3: val_accuracy did not improve from 0.03723\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 33ms/step - accuracy: 0.0374 - loss: 3.3590 - val_accuracy: 0.0372 - val_loss: 3.3582\n",
      "Epoch 4/15\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0386 - loss: 3.3580\n",
      "Epoch 4: val_accuracy did not improve from 0.03723\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 34ms/step - accuracy: 0.0386 - loss: 3.3580 - val_accuracy: 0.0360 - val_loss: 3.3582\n",
      "Epoch 5/15\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0366 - loss: 3.3581\n",
      "Epoch 5: val_accuracy improved from 0.03723 to 0.03794, saving model to model/B_best_model_V1_3.keras\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 34ms/step - accuracy: 0.0366 - loss: 3.3581 - val_accuracy: 0.0379 - val_loss: 3.3583\n",
      "Epoch 6/15\n",
      "\u001b[1m11152/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0380 - loss: 3.3584\n",
      "Epoch 6: val_accuracy did not improve from 0.03794\n",
      "\u001b[1m11153/11153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 34ms/step - accuracy: 0.0380 - loss: 3.3584 - val_accuracy: 0.0379 - val_loss: 3.3581\n",
      "Epoch 7/15\n",
      "\u001b[1m  147/11153\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:56\u001b[0m 32ms/step - accuracy: 0.0402 - loss: 3.3602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=modelconfig.input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(modelconfig.dropout))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(modelconfig.dropout))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(modelconfig.dropout))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(modelconfig.dropout))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(modelconfig.dropout*2))\n",
    "model.add(layers.Dense(modelconfig.num_classes, activation='softmax'))\n",
    "\n",
    "checkpoint_path = \"model/B_best_model_V1_3.keras\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=traingingconfig.epochs,\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "300fc904-5e2d-4ea1-8056-ea2b93cbdcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1396/1396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.0582 - loss: 3.3363\n",
      "Test loss:  3.358131170272827\n",
      "Test accuracy:  0.03600214794278145\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_generator) \n",
    "print('Test loss: ', scores[0])\n",
    "print('Test accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ac46c51-59ae-4c30-a79c-b67c1f4fae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "Predicted Label: W\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model_path = 'model/B_best_model_V1_3.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "img_path = 'asl_alphabet_train/W/100.jpg'\n",
    "img = image.load_img(img_path, color_mode='grayscale', target_size=(32, 32))  # 根据模型输入尺寸调整\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # 增加一个维度，用于批量预测\n",
    "img_array = img_array / 255.0  # 归一化\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = model.predict(img_array)\n",
    "predicted_label = labels[np.argmax(predictions)]\n",
    "\n",
    "# 输出预测结果\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121e2b4-0af1-49ed-ae00-9d0e99dbfc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
